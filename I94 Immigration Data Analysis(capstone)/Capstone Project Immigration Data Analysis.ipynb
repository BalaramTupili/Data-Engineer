{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Analysis on Imagration Events\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The project goal is to build an ETL pipeline to process I94 immigration data and city temperature data.\n",
    "Then it will be used to analyze whether temperature of city will influence immigration events.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, year, month, col, isnull\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import DateType\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "Two datasets are used in this project:\n",
    "\n",
    "    1. City temperature    --   Has Average temperature city level.\n",
    "    2. I94 immigration     --   Has data related immigration events\n",
    "\n",
    "City temperature data will be aggregated on the city level that will be used to join with I94 immigration data using i94port column and figure out will immigrants choose a city based on destination city temperature.\n",
    "\n",
    "\n",
    "Spark is used in this project to handle large data like I94 immigration data.\n",
    "\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "#### Data Sets\n",
    "\n",
    "**World Temperature Data :** Data comes from [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "It is in csv format and contains world temparature data.\n",
    ">**Important Columns**\n",
    ">- AverageTemperature = average temperature\n",
    ">- City = city name\n",
    ">- Country = country name\n",
    "\n",
    " **I94 Immigration Data:** Data comes from [US National Tourism and Trade Office](https://travel.trade.gov/research/reports/i94/historical/2016.html).It is in SAS7BDAT format and contains immigration events.\n",
    ">**Important Columns**\n",
    ">- cicid  = This is the unique Identifier\n",
    ">- i94yr  = 4 digit year of the arrival\n",
    ">- i94mon = numeric month of the arrival\n",
    ">- i94cit = 3 digit code of origin city\n",
    ">- i94port = 3 character code of destination city\n",
    ">- arrdate = arrival date in the USA\n",
    ">- i94mode = 1 digit travel code\n",
    ">- depdate = departure date from the USA\n",
    ">- i94visa = reason for immigration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "temparatureData = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../../data2/GlobalLandTemperaturesByCity.csv\")\n",
    "immigrationData = spark.read.format('com.github.saurfang.sas.spark').load(\"../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing first five rows\n",
    "temparatureData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+-----------+-----------+----------+-----------+-------------+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|validres|delete_days|delete_mexl|delete_dup|delete_visa|delete_recdup|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|         admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+-----------+-----------+----------+-----------+-------------+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|  4.0|2016.0|   6.0| 135.0| 135.0|    XXX|20612.0|   null|   null|   null|  59.0|    2.0|  1.0|     1.0|        0.0|        0.0|       0.0|        0.0|          0.0|    null|    null| null|      Z|   null|      U|   null| 1957.0|10032016|  null|  null|   null|1.4938462027E10| null|      WT|\n",
      "|  5.0|2016.0|   6.0| 135.0| 135.0|    XXX|20612.0|   null|   null|   null|  50.0|    2.0|  1.0|     1.0|        0.0|        0.0|       0.0|        0.0|          0.0|    null|    null| null|      Z|   null|      U|   null| 1966.0|10032016|  null|  null|   null|1.7460063727E10| null|      WT|\n",
      "|  6.0|2016.0|   6.0| 213.0| 213.0|    XXX|20609.0|   null|   null|   null|  27.0|    3.0|  1.0|     1.0|        0.0|        0.0|       0.0|        0.0|          0.0|    null|    null| null|      T|   null|      U|   null| 1989.0|     D/S|  null|  null|   null|  1.679297785E9| null|      F1|\n",
      "|  7.0|2016.0|   6.0| 213.0| 213.0|    XXX|20611.0|   null|   null|   null|  23.0|    3.0|  1.0|     1.0|        0.0|        0.0|       0.0|        0.0|          0.0|    null|    null| null|      T|   null|      U|   null| 1993.0|     D/S|  null|  null|   null|  1.140963185E9| null|      F1|\n",
      "| 16.0|2016.0|   6.0| 245.0| 245.0|    XXX|20632.0|   null|   null|   null|  24.0|    3.0|  1.0|     1.0|        0.0|        0.0|       0.0|        0.0|          0.0|    null|    null| null|      T|   null|      U|   null| 1992.0|     D/S|  null|  null|   null|  1.934535285E9| null|      F1|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+-----------+-----------+----------+-----------+-------------+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing first five rows\n",
    "immigrationData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "**World Temperature Data :** By seeing above sample data we can observe that AverageTemperature has null values.\n",
    "\n",
    "**I94 Immigration Data:** We will clean i94yr column which contains invalid values(XXX, 99, NaN, etc).We will filter \n",
    "i94yr columns with valid values presnt in I94_SAS_Labels_Descriptions file.\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#i94port city and their respective code is stored in key value in python dictionary\n",
    "fname = r'destination_city.txt'\n",
    "city_and_code = {}\n",
    "with open(fname) as f:\n",
    "    for line in f:\n",
    "        words = line.split('\\'')\n",
    "        city = words[3].split(',')[0].lower()\n",
    "        code = words[1]\n",
    "        city_and_code[city] = code    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#creating user defined function thaat takes city name and returns city code if exists else None\n",
    "@udf\n",
    "def getCitybyCode(city):\n",
    "    code = city_and_code.get(city.lower())\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#we filtered country to do analysis on us data and filtered dt column only latest year because immigration data contains only 2016 dat\n",
    "temparatureData = temparatureData.filter(year(col(\"dt\"))==2013)\\\n",
    ".filter(col(\"Country\")==\"United States\")\\\n",
    ".filter(col(\"AverageTemperature\") != 'NaN')\\\n",
    ".withColumn(\"i94port\",getCitybyCode(col(\"City\")))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temparatureData.createOrReplaceTempView(\"temparatureTbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#filtering non null columns averaging temparature column based on required columns\n",
    "temparatureClean = spark.sql('''\n",
    "select i94port, City, Country, round(avg(AverageTemperature),2) as AVGCityTemparature from  temparatureTbl \n",
    "where i94port is not null\n",
    "group by i94port, City, Country\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- AVGCityTemparature: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temparatureClean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------------+------------------+\n",
      "|i94port|        City|      Country|AVGCityTemparature|\n",
      "+-------+------------+-------------+------------------+\n",
      "|    GRP|Grand Rapids|United States|             10.76|\n",
      "|    NOG|     Nogales|United States|             19.71|\n",
      "|    NWH|   New Haven|United States|             12.33|\n",
      "|    JAC|Jacksonville|United States|             22.49|\n",
      "|    KAN| Kansas City|United States|             13.99|\n",
      "+-------+------------+-------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temparatureClean.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Clean immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cleanImmigirationData(file):\n",
    "    \"\"\"\n",
    "    Input: Takes file that is in SAS7BDAT format.\n",
    "    Output: cleans the file and returns dataframe\n",
    "    \"\"\"\n",
    "    df = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "    \n",
    "    df = df.filter(df.i94addr.isNotNull())\\\n",
    "            .filter(df.i94res.isNotNull())\\\n",
    "            .filter(df.i94port.isin(list(city_and_code.values())))\\\n",
    "            .withColumn(\"Year\",col(\"i94yr\").cast(\"integer\"))\\\n",
    "            .withColumn(\"Month\",col(\"i94mon\").cast(\"integer\"))\n",
    "    df = df.select(\"cicid\",\"Year\",\"Month\",col(\"i94cit\").alias(\"OriginCity\"),col(\"i94port\").alias(\"DestiCity\"),\\\n",
    "                   \"arrdate\",col(\"i94mode\").alias(\"TravelMode\"),\"depdate\",col(\"i94visa\").alias(\"VisaReason\"))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "sas_files = glob('../../data/18-83510-I94-Data-2016/*.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "for file in sas_files:\n",
    "    df = cleanImmigirationData(file)\n",
    "    df.write.mode('append').parquet(\"immigration_files/i94immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "ImmigirationData = spark.read.parquet(\"immigration_files/i94immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- OriginCity: double (nullable = true)\n",
      " |-- DestiCity: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- TravelMode: double (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- VisaReason: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ImmigirationData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----+----------+---------+-------+----------+-------+----------+\n",
      "|    cicid|Year|Month|OriginCity|DestiCity|arrdate|TravelMode|depdate|VisaReason|\n",
      "+---------+----+-----+----------+---------+-------+----------+-------+----------+\n",
      "|6642585.0|2016|   12|     204.0|      BOS|20817.0|       1.0|20826.0|       2.0|\n",
      "|6642586.0|2016|   12|     129.0|      BOS|20817.0|       1.0|20831.0|       2.0|\n",
      "|6642587.0|2016|   12|     691.0|      MIA|20817.0|       1.0|20827.0|       2.0|\n",
      "|6642588.0|2016|   12|     135.0|      NYC|20817.0|       1.0|20826.0|       2.0|\n",
      "|6642590.0|2016|   12|     209.0|      NEW|20817.0|       1.0|20819.0|       2.0|\n",
      "+---------+----+-----+----------+---------+-------+----------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ImmigirationData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "We will follow start Schema \n",
    "\n",
    "**Dimension Tables**\n",
    "\n",
    "**DimTemperature :**  It contains average temparature city in U.S.\n",
    "* i94port = code for city\n",
    "* AverageTemperature = average temperature\n",
    "* City = city name\n",
    "* Country = country name\n",
    "\n",
    "\n",
    "**DimImmigration:**   It contains immigration events.\n",
    "* cicid  = This is the unique Identifier\n",
    "* Year  = 4 digit year of the arrival\n",
    "* Month = numeric month of the arrival\n",
    "* OriginCity = 3 digit code of origin city\n",
    "* DestiCity = 3 character code of destination city\n",
    "* Arrdate = arrival date in the USA\n",
    "* TravelMode = 1 digit travel code\n",
    "* Depdate = departure date from the USA\n",
    "* VisaReason = reason for immigration\n",
    "\n",
    "**Fact Table**\n",
    "**FactImmigration Data:**   It contains data from both immigration and  temparature dimension tables joined based on i94port(DestiCity).\n",
    "* cicid  = This is the unique Identifier\n",
    "* Year  = 4 digit year of the arrival\n",
    "* Month = numeric month of the arrival\n",
    "* OriginCity = 3 digit code of origin city\n",
    "* DestiCity = 3 character code of destination city\n",
    "* Arrdate = arrival date in the USA\n",
    "* TravelMode = 1 digit travel code\n",
    "* Depdate = departure date from the USA\n",
    "* VisaReason = reason for immigration\n",
    "* AverageTemperature = average temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "    1.DimTemperature is crested by reading data from csv file and aggregated data after cleaning (completed instep 2)\n",
    "\n",
    "    2.DimImmigration is created from list of sas files and cleaned (completed instep 2)\n",
    "\n",
    "    3.FactImmigration is created by joining i94port(DestiCity) by using DimTemperature and DimImmigration tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model.\n",
    "\n",
    "we already cleaned data in step 2 now we will use those dataframes and store them in a parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "ImmigirationData.createOrReplaceTempView(\"dimImmig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temparatureClean.createOrReplaceTempView(\"dimTemp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fact table created using two dim tables by joining i94port\n",
    "factImmig = spark.sql('''\n",
    "SELECT im.cicid,\n",
    "       im.Year,\n",
    "       im.Month,\n",
    "       im.OriginCity,\n",
    "       im.arrdate,\n",
    "       im.depdate,\n",
    "       im.VisaReason ,\n",
    "       tmp.AVGCityTemparature as Citytemperature,\n",
    "       tmp.City as DesitinationCity,\n",
    "       tmp.i94port\n",
    "FROM dimImmig  im\n",
    "JOIN dimTemp  tmp ON (im.DestiCity = tmp.i94port)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- OriginCity: double (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- VisaReason: double (nullable = true)\n",
      " |-- Citytemperature: double (nullable = true)\n",
      " |-- DesitinationCity: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "factImmig.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "factImmig.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/target/factImmigiration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temparatureClean.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/target/dimTemparature.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "factImmig.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/target/dimImmigiration.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32548841"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "# we will check counts\n",
    "factImmig.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temparatureClean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32548841"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factImmig.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|   id|\n",
      "+-----+\n",
      "|false|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# will check for null values in unique columns\n",
    "factImmig.select(isnull('cicid').alias('imgID')).dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|tempID|\n",
      "+------+\n",
      "| false|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temparatureClean.select(isnull('i94port').alias('tempID')).dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|factID|\n",
      "+------+\n",
      "| false|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "factImmig.select(isnull('cicid').alias('factID')).dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from.\n",
    "\n",
    "\n",
    "**Dimension Tables**\n",
    "\n",
    "**DimTemperature :**  It contains average temparature city in U.S.\n",
    "* i94port = code for city\n",
    "* AverageTemperature = average temperature\n",
    "* City = city name\n",
    "* Country = country name\n",
    "\n",
    "\n",
    "**DimImmigration:**   It contains immigration events.\n",
    "* cicid  = This is the unique Identifier\n",
    "* Year  = 4 digit year of the arrival\n",
    "* Month = numeric month of the arrival\n",
    "* OriginCity = 3 digit code of origin city\n",
    "* DestiCity = 3 character code of destination city\n",
    "* Arrdate = arrival date in the USA\n",
    "* TravelMode = 1 digit travel code\n",
    "* Depdate = departure date from the USA\n",
    "* VisaReason = reason for immigration\n",
    "\n",
    "**Fact Table**\n",
    "**FactImmigration Data:**   It contains data from both immigration and  temparature dimension tables joined based on i94port(DestiCity).\n",
    "* cicid  = This is the unique Identifier\n",
    "* Year  = 4 digit year of the arrival\n",
    "* Month = numeric month of the arrival\n",
    "* OriginCity = 3 digit code of origin city\n",
    "* DestiCity = 3 character code of destination city\n",
    "* Arrdate = arrival date in the USA\n",
    "* TravelMode = 1 digit travel code\n",
    "* Depdate = departure date from the USA\n",
    "* VisaReason = reason for immigration\n",
    "* AverageTemperature = average temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "  Python is used here as a programming language it is easy to maintain and read.\n",
    "  It has vast libraries we can use to deal with different files\n",
    "  \n",
    "  Spark is used because it processes data fast compared to Hadoop.\n",
    "  It has API in python that is easy to implement ETL pipeline\n",
    "\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "    It mostly depends on the requirement of users.\n",
    "    If needed Data can be updated incrementally on a daily basis.\n",
    "    so, that it will be analyzed to make business decisions on the current trend.\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "\n",
    "* The data was increased by 100x.\n",
    " \n",
    "     We will use spark with more nodes for processing and use s3 as a data lake.\n",
    "     It has in-memory processing capability and faster than Hadoop.\n",
    "     Files in s3 can be used to build cloud data warehouse using redshift.\n",
    "\n",
    "\n",
    "* The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " \n",
    "    we will use Airflow to schedule jobs on a daily basis.\n",
    "    We will configure mail alerts and data quality checks.\n",
    "\n",
    "\n",
    "* The database needed to be accessed by 100+ people.\n",
    " \n",
    "    we can use AWS Redshift as it is petabyte scalable.\n",
    "    we will enable auto-scaling and copies of data is made available in different region near to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
